{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70bb66d9-4eaf-4982-9878-5a7d1de406e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dhruvsharma/Large Scale\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18e4f8c3-7f41-4789-a06b-836f4c74f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 426880 rows and 26 columns.\n",
      "Columns in the dataset:\n",
      "Index(['id', 'url', 'region', 'region_url', 'price', 'year', 'manufacturer',\n",
      "       'model', 'condition', 'cylinders', 'fuel', 'odometer', 'title_status',\n",
      "       'transmission', 'VIN', 'drive', 'size', 'type', 'paint_color',\n",
      "       'image_url', 'description', 'county', 'state', 'lat', 'long',\n",
      "       'posting_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path to your CSV\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles.csv'\n",
    "\n",
    "# Load CSV data into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = data.shape\n",
    "\n",
    "# Print the number of rows\n",
    "print(f\"The dataset has {num_rows} rows and {num_columns} columns.\")\n",
    "\n",
    "print(\"Columns in the dataset:\")\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e38c56ef-b2a8-4dbe-ad11-fd4ee1d934cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'id' is a unique identifier.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/vehicles 3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Column to check (e.g., 'ID')\n",
    "column_to_check = 'id'\n",
    "\n",
    "# Check if the column is unique\n",
    "is_unique = data[column_to_check].is_unique\n",
    "\n",
    "# Print the result\n",
    "if is_unique:\n",
    "    print(f\"'{column_to_check}' is a unique identifier.\")\n",
    "else:\n",
    "    print(f\"'{column_to_check}' is NOT a unique identifier. There are duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ea57f62-fb14-4de7-9950-afb9a5fc6193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Quality Checks...\n",
      "\n",
      "1. Checking for Null Values...\n",
      "âŒ The data contains null values.\n",
      "Columns with null values:\n",
      "year              1205\n",
      "manufacturer     17646\n",
      "model             5277\n",
      "condition       174104\n",
      "cylinders       177678\n",
      "fuel              3013\n",
      "odometer          4400\n",
      "title_status      8242\n",
      "transmission      2556\n",
      "VIN             161042\n",
      "drive           130567\n",
      "size            306361\n",
      "type             92858\n",
      "paint_color     130203\n",
      "image_url           68\n",
      "description         70\n",
      "county          426880\n",
      "lat               6549\n",
      "long              6549\n",
      "posting_date        68\n",
      "dtype: int64\n",
      "2. Checking for Duplicate Rows...\n",
      "âœ… No duplicate rows found.\n",
      "\n",
      "3. Checking if ['id'] form a unique identifier...\n",
      "âœ… The column(s) ['id'] form a unique identifier.\n",
      "\n",
      "4. Checking Data Type Consistency...\n",
      "Detected Data Types:\n",
      "id                int64\n",
      "url              object\n",
      "region           object\n",
      "region_url       object\n",
      "price             int64\n",
      "year            float64\n",
      "manufacturer     object\n",
      "model            object\n",
      "condition        object\n",
      "cylinders        object\n",
      "fuel             object\n",
      "odometer        float64\n",
      "title_status     object\n",
      "transmission     object\n",
      "VIN              object\n",
      "drive            object\n",
      "size             object\n",
      "type             object\n",
      "paint_color      object\n",
      "image_url        object\n",
      "description      object\n",
      "county          float64\n",
      "state            object\n",
      "lat             float64\n",
      "long            float64\n",
      "posting_date     object\n",
      "dtype: object\n",
      "âŒ There are columns with inconsistent data types.\n",
      "\n",
      "âš ï¸ Data may need cleaning. Please review the checks above for details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_data_quality(file_path, unique_columns=None):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Initialize status flag\n",
    "    data_is_clean = True\n",
    "\n",
    "    print(\"Starting Data Quality Checks...\\n\")\n",
    "    \n",
    "    # 1. Check for Null Values\n",
    "    print(\"1. Checking for Null Values...\")\n",
    "    if data.isnull().values.any():\n",
    "        print(\"âŒ The data contains null values.\")\n",
    "        print(\"Columns with null values:\")\n",
    "        print(data.isnull().sum()[data.isnull().sum() > 0])\n",
    "        data_is_clean = False\n",
    "    else:\n",
    "        print(\"âœ… No null values found in the data.\\n\")\n",
    "    \n",
    "    # 2. Check for Duplicate Rows\n",
    "    print(\"2. Checking for Duplicate Rows...\")\n",
    "    if data.duplicated().any():\n",
    "        print(\"âŒ The data contains duplicate rows.\")\n",
    "        print(f\"Number of duplicate rows: {data.duplicated().sum()}\")\n",
    "        data_is_clean = False\n",
    "    else:\n",
    "        print(\"âœ… No duplicate rows found.\\n\")\n",
    "    \n",
    "    # 3. Check if the specified column(s) are unique (Unique Identifier Check)\n",
    "    if unique_columns:\n",
    "        print(f\"3. Checking if {unique_columns} form a unique identifier...\")\n",
    "        if data.duplicated(subset=unique_columns).any():\n",
    "            print(f\"âŒ The column(s) {unique_columns} do not form a unique identifier. There are duplicates.\")\n",
    "            data_is_clean = False\n",
    "        else:\n",
    "            print(f\"âœ… The column(s) {unique_columns} form a unique identifier.\\n\")\n",
    "    else:\n",
    "        print(\"3. Skipping unique identifier check since no unique columns were provided.\\n\")\n",
    "    \n",
    "    # 4. Check Data Type Consistency\n",
    "    print(\"4. Checking Data Type Consistency...\")\n",
    "    print(\"Detected Data Types:\")\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    if data.select_dtypes(include=['object']).apply(pd.to_numeric, errors='coerce').isnull().sum().sum() > 0:\n",
    "        print(\"âŒ There are columns with inconsistent data types.\")\n",
    "        data_is_clean = False\n",
    "    else:\n",
    "        print(\"âœ… Data types are consistent.\\n\")\n",
    "    \n",
    "    # Final Result\n",
    "    if data_is_clean:\n",
    "        print(\"\\nðŸŽ‰ Data is well maintained and doesn't need any cleaning!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Data may need cleaning. Please review the checks above for details.\")\n",
    "        \n",
    "\n",
    "# File path to your CSV\n",
    "file_path = '/Users/Desktop/Project/vehicles 3.csv'\n",
    "\n",
    "# Column or combination of columns to check as a unique identifier (set this to the appropriate column or leave as None)\n",
    "unique_columns = ['id']  # Replace with your identifier column(s), if applicable\n",
    "\n",
    "# Run the data quality checker\n",
    "check_data_quality(file_path, unique_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b907159-68a0-4115-8edf-dec94be9f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae5cc030-4e14-4aa8-bd1e-af99e9a76a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with remaining null values after cleaning:\n",
      "county    426880\n",
      "dtype: int64\n",
      "\n",
      "Data Types after cleaning:\n",
      "id                int64\n",
      "url              object\n",
      "region           object\n",
      "region_url       object\n",
      "price             int64\n",
      "year              int64\n",
      "manufacturer     object\n",
      "model            object\n",
      "condition        object\n",
      "cylinders        object\n",
      "fuel             object\n",
      "odometer        float64\n",
      "title_status     object\n",
      "transmission     object\n",
      "VIN              object\n",
      "drive            object\n",
      "size             object\n",
      "type             object\n",
      "paint_color      object\n",
      "image_url        object\n",
      "description      object\n",
      "county          float64\n",
      "state            object\n",
      "lat             float64\n",
      "long            float64\n",
      "posting_date     object\n",
      "dtype: object\n",
      "\n",
      "Cleaned data saved to /Users/Desktop/Project/Files/cleaned_vehicles.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/Desktop/Project/vehicles 3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Handle Null Values\n",
    "# Strategy: Fill nulls in numeric columns with the median, and for object columns with the mode\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'float64' or data[column].dtype == 'int64':\n",
    "        data[column].fillna(data[column].median(), inplace=True)\n",
    "    elif data[column].dtype == 'object':\n",
    "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "\n",
    "# 2. Convert Data Types Consistently\n",
    "# Let's cast columns to their proper data types based on expected values\n",
    "data['year'] = pd.to_numeric(data['year'], errors='coerce').fillna(0).astype('int64')\n",
    "data['price'] = pd.to_numeric(data['price'], errors='coerce').fillna(0).astype('int64')\n",
    "data['odometer'] = pd.to_numeric(data['odometer'], errors='coerce').fillna(0).astype('float64')\n",
    "data['lat'] = pd.to_numeric(data['lat'], errors='coerce').fillna(0).astype('float64')\n",
    "data['long'] = pd.to_numeric(data['long'], errors='coerce').fillna(0).astype('float64')\n",
    "\n",
    "# Convert other object columns to string (to handle mixed types)\n",
    "object_columns = data.select_dtypes(include=['object']).columns\n",
    "data[object_columns] = data[object_columns].astype(str)\n",
    "\n",
    "# 3. Re-run Data Quality Checks to Validate\n",
    "# Checking for remaining null values\n",
    "null_counts = data.isnull().sum()\n",
    "print(\"Columns with remaining null values after cleaning:\")\n",
    "print(null_counts[null_counts > 0])\n",
    "\n",
    "# Check data types again\n",
    "print(\"\\nData Types after cleaning:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Save the cleaned data\n",
    "cleaned_file_path = '/Users/Desktop/Project/Files/cleaned_vehicles.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\nCleaned data saved to {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "405b2467-fc46-4672-a713-3962ad28cf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yy/ld755vq92yb4vjb5fqht2qjr0000gn/T/ipykernel_1086/3836716501.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'United States' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df['county'].fillna('United States', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   region         county\n",
      "0                prescott  United States\n",
      "1            fayetteville  United States\n",
      "2            florida keys  United States\n",
      "3  worcester / central MA  United States\n",
      "4              greensboro  United States\n",
      "Updated CSV file with modified county column saved to /Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the old CSV file\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles.csv'\n",
    "\n",
    "# Path for the new cleaned CSV file\n",
    "output_file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles_data.csv'\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace null values in the 'county' column with 'United States'\n",
    "df['county'].fillna('United States', inplace=True)\n",
    "\n",
    "# Check the resulting DataFrame to ensure the county column is correctly populated\n",
    "print(df[['region', 'county']].head())\n",
    "\n",
    "# Save the updated DataFrame back to CSV with the updated 'county' column\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV file with modified county column saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d55d3-c07f-49d1-9780-7f0223ab350a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
