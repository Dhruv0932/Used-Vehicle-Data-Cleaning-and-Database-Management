{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2a9619-e062-4fc1-b6f0-ed5b1f10e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: sqlalchemy in /opt/anaconda3/lib/python3.11/site-packages (2.0.25)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading psycopg2_binary-2.9.9-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73408db6-caca-4daf-81d8-2ebf3a5b8c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yy/ld755vq92yb4vjb5fqht2qjr0000gn/T/ipykernel_1084/2136377226.py:36: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  data['posting_date'] = pd.to_datetime(data['posting_date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "426880 rows of vehicle data inserted successfully into the Vehicles table in schema 'vehicles'!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "# Path to the cleaned CSV data\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles_data.csv'\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_user = 'postgres'\n",
    "db_password = urllib.parse.quote_plus('newpassword')  \n",
    "db_host = 'localhost'\n",
    "db_port = '5433'\n",
    "db_name = 'postgres'\n",
    "schema_name = 'vehicles'  \n",
    "\n",
    "# Create connection engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Mapping of CSV columns to SQL table columns\n",
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'price': 'price',\n",
    "    'year': 'year',\n",
    "    'odometer': 'odometer',\n",
    "    'VIN': 'vin', \n",
    "    'posting_date': 'posting_date'\n",
    "}\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Rename the columns to match the PostgreSQL table\n",
    "data = data.rename(columns=column_mapping)\n",
    "\n",
    "# Convert posting_date to a date format and coerce errors to NaT (Not a Timestamp)\n",
    "data['posting_date'] = pd.to_datetime(data['posting_date'], errors='coerce')\n",
    "\n",
    "# Check for any rows where the posting_date couldn't be parsed\n",
    "invalid_dates = data[data['posting_date'].isna()]\n",
    "\n",
    "if not invalid_dates.empty:\n",
    "    print(\"Warning: The following rows have invalid 'posting_date' values and will be set to NaT:\")\n",
    "    print(invalid_dates[['id', 'posting_date']])\n",
    "\n",
    "# Insert data into the Vehicles table within the specified schema\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection successful!\")\n",
    "        \n",
    "        # Insert all data into the Vehicles table within the specified schema\n",
    "        data[['id', 'price', 'year', 'odometer', 'vin', 'posting_date']].to_sql(\n",
    "            'vehicles', \n",
    "            connection, \n",
    "            schema='vehicles',  # Specify the schema\n",
    "            if_exists='append', \n",
    "            index=False\n",
    "        )\n",
    "        print(f\"{len(data)} rows of vehicle data inserted successfully into the Vehicles table in schema '{schema_name}'!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during data insertion: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f39ff6-d703-4286-abfc-19195a8caf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#region Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05e3777b-107c-4224-9854-eb45ec0462a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "426880 rows of region data inserted successfully into the 'vehicles.Region' table!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "# Path to the cleaned CSV data\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles_data.csv'  # Updated file path\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_user = 'postgres'\n",
    "db_password = urllib.parse.quote_plus('newpassword') \n",
    "db_host = 'localhost'\n",
    "db_port = '5433'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create connection engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Map columns from the CSV to the Region table\n",
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'region': 'region',\n",
    "    'region_url': 'region_url',\n",
    "    'county': 'county',\n",
    "    'state': 'state',\n",
    "    'lat': 'lat',\n",
    "    'long': 'long'\n",
    "}\n",
    "\n",
    "# Select and rename the necessary columns for the Region table\n",
    "region_data = data[['id', 'region', 'region_url', 'county', 'state', 'lat', 'long']].rename(columns=column_mapping)\n",
    "\n",
    "# Insert the data into the existing Region table in the 'vehicles' schema\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection successful!\")\n",
    "        \n",
    "        # Insert the region data into the Region table under the vehicles schema\n",
    "        region_data.to_sql('region', connection, schema='vehicles', if_exists='append', index=False)\n",
    "        print(f\"{len(region_data)} rows of region data inserted successfully into the 'vehicles.Region' table!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during data insertion: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e6b9a-0b13-4530-89df-547a5e4ce6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#script for Manufacture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e152164-d767-42bf-a09c-399b78cac802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "426880 rows of manufacturer and model data inserted successfully into the 'vehicles.manufacturer_model' table!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "# Path to the cleaned CSV data\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles_data.csv'\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_user = 'postgres'\n",
    "db_password = urllib.parse.quote_plus('newpassword')  \n",
    "db_host = 'localhost'\n",
    "db_port = '5433'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create connection engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Map columns from the CSV to the ManufacturerModel table\n",
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'manufacturer': 'manufacturer',\n",
    "    'model': 'model'\n",
    "}\n",
    "\n",
    "# Select and rename the necessary columns for the ManufacturerModel table\n",
    "manufacturer_model_data = data[['id', 'manufacturer', 'model']].rename(columns=column_mapping)\n",
    "\n",
    "# Insert the data into the existing ManufacturerModel table in the 'vehicles' schema\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection successful!\")\n",
    "        \n",
    "        # Insert the manufacturer_model data into the ManufacturerModel table under the vehicles schema\n",
    "        manufacturer_model_data.to_sql('manufacturer_model', connection, schema='vehicles', if_exists='append', index=False)\n",
    "        print(f\"{len(manufacturer_model_data)} rows of manufacturer and model data inserted successfully into the 'vehicles.manufacturer_model' table!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during data insertion: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2a716-0141-451e-a7f4-211a1caeb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#script for vehicledetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cd29f42-6e47-4ebc-a84a-6fab385fdf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "426880 rows of vehicle details inserted successfully into the 'vehicles.vehicle_details' table!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "# Path to the cleaned CSV data\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles_data.csv'\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_user = 'postgres'\n",
    "db_password = urllib.parse.quote_plus('newpassword') \n",
    "db_host = 'localhost'\n",
    "db_port = '5433'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create connection engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Map columns from the CSV to the VehicleDetails table\n",
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'condition': 'condition',\n",
    "    'cylinders': 'cylinders',\n",
    "    'fuel': 'fuel',\n",
    "    'title_status': 'title_status',\n",
    "    'transmission': 'transmission',\n",
    "    'drive': 'drive',\n",
    "    'size': 'size',\n",
    "    'type': 'type',\n",
    "    'paint_color': 'paint_color'\n",
    "}\n",
    "\n",
    "# Select and rename the necessary columns for the VehicleDetails table\n",
    "vehicle_details_data = data[['id', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color']].rename(columns=column_mapping)\n",
    "\n",
    "# Insert the data into the existing VehicleDetails table in the 'vehicles' schema\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection successful!\")\n",
    "        \n",
    "        # Insert the vehicle details data into the VehicleDetails table under the vehicles schema\n",
    "        vehicle_details_data.to_sql('vehicle_details', connection, schema='vehicles', if_exists='append', index=False)\n",
    "        print(f\"{len(vehicle_details_data)} rows of vehicle details inserted successfully into the 'vehicles.vehicle_details' table!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during data insertion: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342946c-9d5a-4b15-90b0-658d5f26f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#script for Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "813476da-e5db-4762-a703-51ca8cb414b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "426880 rows of media data inserted successfully into the 'vehicles.media' table!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "\n",
    "# Path to the cleaned CSV data\n",
    "file_path = '/Users/dhruvsharma/Desktop/Project/Files/cleaned_vehicles_data.csv'\n",
    "\n",
    "# PostgreSQL connection details\n",
    "db_user = 'postgres'\n",
    "db_password = urllib.parse.quote_plus('newpassword')  \n",
    "db_host = 'localhost'\n",
    "db_port = '5433'\n",
    "db_name = 'postgres'\n",
    "\n",
    "# Create connection engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Map columns from the CSV to the Media table\n",
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'url': 'url',\n",
    "    'image_url': 'image_url',\n",
    "    'description': 'description'\n",
    "}\n",
    "\n",
    "# Select and rename the necessary columns for the Media table\n",
    "media_data = data[['id', 'url', 'image_url', 'description']].rename(columns=column_mapping)\n",
    "\n",
    "# Insert the data into the existing Media table in the 'vehicles' schema\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection successful!\")\n",
    "        \n",
    "        # Insert the media data into the Media table under the vehicles schema\n",
    "        media_data.to_sql('media', connection, schema='vehicles', if_exists='append', index=False)\n",
    "        print(f\"{len(media_data)} rows of media data inserted successfully into the 'vehicles.media' table!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during data insertion: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
